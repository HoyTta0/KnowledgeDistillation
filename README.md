# çŸ¥è¯†è’¸é¦åœ¨æ–‡æœ¬æ–¹å‘ä¸Šçš„åº”ç”¨
![test](https://img.shields.io/badge/HOY-ğŸ‘€-9cf?style=social&logo=appveyor)
![visitors](https://visitor-badge.glitch.me/badge?page_id=HoyTta0.KnowledgeDistillation&left_color=green&right_color=red)  
æ¨¡å‹ç›¸å…³ç­‰å†…å®¹åœ¨[**æˆ‘çš„åšå®¢**](https://blog.csdn.net/HoyTra0/article/details/106238382)æœ‰å…·ä½“ä»‹ç»ã€‚

## ç›®å½•

- [æ›´æ–°æ—¥å¿—](#æ›´æ–°æ—¥å¿—)
- [è¿è¡Œç¯å¢ƒ](#è¿è¡Œç¯å¢ƒ)
- [ä½¿ç”¨è¯´æ˜](#ä½¿ç”¨è¯´æ˜)
- [æ¨¡å‹å®ç°](#æ¨¡å‹å®ç°)
  - [ä»£ç ç»“æ„](#ä»£ç ç»“æ„)
- [æ¨¡å‹æ•ˆæœ](#æ¨¡å‹æ•ˆæœ)
- [å…¬å¼€æ•°æ®é›†æµ‹è¯•æ•ˆæœ](#TNEWSæµ‹è¯•æ•ˆæœ)
- [å·²çŸ¥é—®é¢˜](#å·²çŸ¥é—®é¢˜)
- [TODO](#TODO)
- [å‚è€ƒé“¾æ¥](#å‚è€ƒé“¾æ¥)

## æ›´æ–°æ—¥å¿—

### 2021.11.10

>  å¤§å¹…æ”¹åŠ¨ï¼Œæ•´ç†æ•°æ®æ ¼å¼ï¼Œä¼˜åŒ–ä»£ç ï¼Œä½¿ç”¨æœ€æ–°ç¬¬ä¸‰æ–¹åŒ…ï¼Œæ—§ç‰ˆæœ¬ä»£ç åœ¨v0.1åˆ†æ”¯æŸ¥çœ‹ã€‚

### 2020.08.28

>  æ•´ç†ä»£ç ç»“æ„ï¼ŒæŠ›å¼ƒå€Ÿé‰´çš„Bertæ¨¡å‹ï¼Œå¢åŠ xlnetæ¨¡å‹ï¼Œé¢„è®­ç»ƒxlnetæ¨¡å‹æ•ˆæœè¾ƒå·®ï¼Œå¯ä»¥åœ¨æ¨¡å‹åŸºç¡€ä¸Šå†è¿›è¡Œé¢„è®­ç»ƒï¼Œå› æ­¤æ·»åŠ äº†æ¨¡å‹é¢„è®­ç»ƒä»£ç ã€‚

### 2020.07.15

>  ä¿®å¤bugï¼Œæ·»åŠ textGCNæ¨¡å‹ï¼ˆå•ç‹¬è®­ç»ƒï¼Œæ¨¡å‹æ•ˆæœè¾ƒå·®ï¼‰ã€‚

### 2020.07.06

>  ç§»é™¤æ¨¡å‹ä»‹ç»ï¼†éƒ¨åˆ†æ¨¡å‹å®ç°ï¼Œå¢åŠ ä½¿ç”¨è¯´æ˜åŠè¿è¡Œç¯å¢ƒã€‚

### 2020.05.28

>  å¢åŠ äº†ç›´æ¥ä½¿ç”¨å­¦ç”Ÿæ¨¡å‹è®­ç»ƒä»£ç ï¼Œå¹¶ä½¿ç”¨å…¬å¼€æµ‹è¯•é›†å®Œæˆæµ‹è¯•ã€‚

## è¿è¡Œç¯å¢ƒ

python 3.7

transformers 4.11.3

torch 1.10.0

## ä½¿ç”¨è¯´æ˜

ä¸‹è½½[é¢„è®­ç»ƒBERTæ¨¡å‹å‚æ•° pytorch_model.bin](https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz)æ”¾å…¥KnowledgeDistillation/bert_pretrain



è¿è¡Œ python distill.py

config.pyä¸­train_teacherã€train_studentåˆ†åˆ«è¡¨ç¤ºæ˜¯å¦è®­ç»ƒæ•™å¸ˆæ¨¡å‹ã€è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ã€‚

```python
  å•ç‹¬è®­ç»ƒæ•™å¸ˆæ¨¡å‹      
  self.train_teacher = 1
  self.train_student = 0
  æ•™å¸ˆæ¨¡å‹ä¸å­¦ç”Ÿæ¨¡å‹ä¸²è¡Œè®­ç»ƒï¼ˆè’¸é¦ï¼‰
  self.train_teacher = 1
  self.train_student = 1
  æƒ³è¦å•ç‹¬è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ï¼Œéœ€é…ç½®student.pyä¸­æŸå¤±å‡½æ•°a=1ï¼ŒT=0ï¼Œ
  ä¸”saved_dictä¸­å­˜åœ¨è®­ç»ƒå¥½çš„æ•™å¸ˆæ¨¡å‹teacher.ckptï¼Œå¦åˆ™éœ€è¦å¯¹ä»£ç è¿›è¡Œæ”¹åŠ¨
  self.train_teacher = 0
  self.train_student = 1
```

æƒ³è¦å•ç‹¬è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ï¼Œåªéœ€å°†student.pyä¸­æŸå¤±å‡½æ•°çš„a=1ï¼ŒT=0å³å¯ã€‚

## æ¨¡å‹å®ç°

æ¨¡å‹åŸºæœ¬ä¸Šæ˜¯å¯¹è®ºæ–‡[**Distilling Task-Specific Knowledge from BERT into Simple Neural Networks**](https://arxiv.org/abs/1903.12136
)çš„å¤ç°

### ä»£ç ç»“æ„

Teacheræ¨¡å‹ï¼šBERTæ¨¡å‹

Studentæ¨¡å‹ï¼šä¸€å±‚çš„biLSTM

LOSSå‡½æ•°ï¼šäº¤å‰ç†µ ã€MSE LOSS

çŸ¥è¯†å‡½æ•°ï¼šç”¨æœ€åä¸€å±‚çš„softmaxå‰çš„logitsä½œä¸ºçŸ¥è¯†è¡¨ç¤º

## æ¨¡å‹æ•ˆæœ

å†…éƒ¨æ•°æ®é›†æµ‹è¯•æ•ˆæœã€‚

Teacher

Running time: 116.05915258956909 s

|            | precision | recall | F1-score | support |
| :--------: | :-------: | :----: | :------: | :-----: |
|     0      |   0.91    |  0.84  |   0.87   |  2168   |
|     1      |   0.82    |  0.90  |   0.86   |  1833   |
|  accuracy  |           |        |   0.86   |  4001   |
| macro avg  |   0.86    |  0.87  |   0.86   |  4001   |
| weight avg |   0.87    |  0.86  |   0.86   |  4001   |

Student

Running time: 0.155623197555542 s

|            | precision | recall | F1-score | support |
| :--------: | :-------: | :----: | :------: | :-----: |
|     0      |   0.87    |  0.85  |   0.86   |  2168   |
|     1      |   0.83    |  0.85  |   0.84   |  1833   |
|  accuracy  |           |        |   0.85   |  4001   |
| macro avg  |   0.85    |  0.85  |   0.85   |  4001   |
| weight avg |   0.85    |  0.85  |   0.85   |  4001   |

å¯ä»¥çœ‹å‡ºstudentæ¨¡å‹ä¸teacheræ¨¡å‹ç›¸æ¯”ç²¾åº¦æœ‰ä¸€å®šçš„ä¸¢å¤±ï¼Œè¿™ä¹Ÿå¯ä»¥ç†è§£ï¼Œæ¯•ç«Ÿstudentæ¨¡å‹ç»“æ„ç®€å•ã€‚è€Œåœ¨è¿è¡Œæ—¶é—´ä¸Šå¤§æ¨¡å‹æ˜¯å°æ¨¡å‹çš„746å€ï¼ˆcpuï¼‰ã€‚

## TNEWSæµ‹è¯•æ•ˆæœ

åœ¨æ•°æ®é›†ä¸­é€‰äº†5ç±»å¹¶åšäº†ä¸‹é‡‡æ ·ã€‚ï¼ˆæ­¤éƒ¨åˆ†å…·ä½“è¯´æ˜åç»­å®Œå–„ï¼‰

Student alone

|            | precision | recall | F1-score | support |
| :--------: | :-------: | :----: | :------: | :-----: |
|   story    |  0.6489   | 0.7907 |  0.7128  |   215   |
|   sports   |  0.7669   | 0.7849 |  0.7758  |   767   |
|   house    |  0.7350   | 0.7778 |  0.7558  |   378   |
|    car     |  0.8162   | 0.7522 |  0.7829  |   791   |
|    game    |  0.7319   | 0.7041 |  0.7177  |   659   |
|  accuracy  |           |        |  0.7562  |  2810   |
| macro avg  |  0.7398   | 0.7619 |  0.7490  |  2810   |
| weight avg |  0.7592   | 0.7562 |  0.7567  |  2810   |

Teacher

|            | precision | recall | F1-score | support |
| :--------: | :-------: | :----: | :------: | :-----: |
|   story    |  0.6159   | 0.8651 |  0.7195  |   215   |
|   sports   |  0.8423   | 0.7940 |  0.8174  |   767   |
|   house    |  0.8030   | 0.8519 |  0.8267  |   378   |
|    car     |  0.8823   | 0.7863 |  0.8316  |   791   |
|    game    |  0.7835   | 0.8073 |  0.7952  |   659   |
|  accuracy  |           |        |  0.8082  |  2810   |
| macro avg  |  0.7854   | 0.8209 |  0.7981  |  2810   |
| weight avg |  0.8172   | 0.8082 |  0.8100  |  2810   |

Student 

|            | precision | recall | F1-score | support |
| :--------: | :-------: | :----: | :------: | :-----: |
|   story    |  0.5207   | 0.8186 |  0.6365  |   215   |
|   sports   |  0.8411   | 0.7040 |  0.7665  |   767   |
|   house    |  0.7678   | 0.7698 |  0.7688  |   378   |
|    car     |  0.8104   | 0.7459 |  0.7768  |   791   |
|    game    |  0.6805   | 0.7466 |  0.7120  |   659   |
|  accuracy  |           |        |  0.7434  |  2810   |
| macro avg  |  0.7241   | 0.7570 |  0.7321  |  2810   |
| weight avg |  0.7604   | 0.7434 |  0.7470  |  2810   |

## å·²çŸ¥é—®é¢˜

1. ~~ç›´æ¥ç”¨studentæ¨¡å‹è®­ç»ƒæ•ˆæœå¦‚ä½•ï¼Œæœªåšæµ‹è¯•ã€‚~~ ï¼ˆåœ¨å…¬å¼€æ•°æ®é›†ä¸Šå®Œæˆæµ‹è¯•ï¼Œå¹¶ä¸Šä¼ äº†è®­ç»ƒä»£ç ï¼‰
2. ~~å­¦ç”Ÿæ¨¡å‹ç”¨äº†å¥å‘é‡è¡¨å¾ï¼Œ~~ åŸè®ºæ–‡ç”¨çš„è¯å‘é‡ï¼Œåç»­å·¥ä½œå°†æ¢å›ã€‚
3. ~~æ•™å¸ˆæ¨¡å‹å‚è€ƒäº†åˆ«äººçš„ä»£ç ï¼Œåç»­ä¼šè‡ªå·±æ­BERT~~ã€‚

## TODO

1. å­¦ç”Ÿæ¨¡å‹åŠ è½½é¢„è®­ç»ƒè¯å‘é‡ï¼ˆç›®å‰éšæœºåˆå§‹åŒ–ï¼‰

## å‚è€ƒé“¾æ¥

1. [å¦‚ä½•ç†è§£soft targetè¿™ä¸€åšæ³•ï¼Ÿ  çŸ¥ä¹ YJangoçš„å›ç­”](https://www.zhihu.com/question/50519680?sort=created)

2. [ã€ç»å…¸ç®€è¯»ã€‘çŸ¥è¯†è’¸é¦(Knowledge Distillation) ç»å…¸ä¹‹ä½œ](https://zhuanlan.zhihu.com/p/102038521?utm_source=wechat_timeline)
3. [**Distilling the Knowledge in a Neural Network**](https://arxiv.org/abs/1503.02531  )
4. [**Distilling Task-Specific Knowledge from BERT into Simple Neural Networks**](https://arxiv.org/abs/1903.12136
   )
5. [Chinese-Word-Vectors](https://github.com/Embedding/Chinese-Word-Vectors)
